# Нейронные сети

# Градиентный спуск

Градиентный спуск - это метод оптимизации, используемый для нахождения минимума (или максимума) функции путем итеративного движения в направлении, обратном градиенту функции. Он широко применяется в обучении нейронных сетей для обновления весов сети с целью минимизации функции потерь.

### **Основные идеи**

1. **Итеративное обновление:** Градиентный спуск обновляет веса (параметры) модели на каждом шаге в направлении, противоположном градиенту функции потерь, чтобы минимизировать эту функцию.
2. **Использование градиента:** Метод использует информацию о градиенте функции потерь по отношению к параметрам модели для определения направления наискорейшего убывания функции.
3. **Выбор скорости обучения:** Скорость обучения (learning rate) контролирует размер шага, делаемого в направлении градиента. Это важный гиперпараметр, который может влиять на скорость сходимости и стабильность процесса обучения.

### **Преимущества**

- Простота реализации и понимания.
- Эффективен для многих задач оптимизации.
- Может использоваться для обучения больших моделей с миллионами параметров.

### **Недостатки**

- Может застревать в локальных минимумах, особенно для неудачно выбранных начальных значений параметров.
- Медленная сходимость на плоских участках функции потерь.
- Чувствителен к выбору скорости обучения и другим гиперпараметрам.

**Формула:**
Пусть у нас есть функция потерь $L(w)$, где $w$ - параметры модели. Градиент функции потерь по параметрам $\nabla L(w)$ определяется как вектор частных производных функции потерь по каждому параметру $w_i$:
$\nabla L(w) = \left( \frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial w_2}, \ldots, \frac{\partial L}{\partial w_n} \right)$

Градиентный спуск обновляет параметры $w$ на каждом шаге по формуле:
$w := w - \alpha \nabla L(w)$

Где $\alpha$ - скорость обучения (learning rate), определяющая величину шага.

# Backpropagation

Обратное распространение ошибки (backpropagation) - это алгоритм обратного распространения ошибки, используемый для обновления весов нейронной сети во время обучения. Он является ключевым компонентом в обучении нейронных сетей и позволяет эффективно вычислять градиенты функции потерь по параметрам сети.

### **Принцип работы**

1. **Прямой проход (forward pass):** На этом этапе для каждого входного примера вычисляются выходы каждого слоя нейронной сети, начиная с входного слоя и заканчивая выходным.
2. **Обратный проход (backward pass):** После завершения прямого прохода, вычисляются градиенты функции потерь по параметрам сети с использованием метода обратного распространения ошибки. Эти градиенты передаются от выходного слоя к входному, и каждый слой вычисляет свой вклад в ошибку.
3. **Обновление весов:** Полученные градиенты затем используются для обновления весов сети с помощью градиентного спуска или других методов оптимизации.

$*\frac{\partial L}{\partial w_{ij}} = \frac{\partial L}{\partial z_{j}} \cdot \frac{\partial z_{j}}{\partial w_{ij}}*$

Где $*z_i*$ - промежуточные переменные между слоями сети. Это позволяет эффективно передавать градиенты через различные слои сети, начиная с выходного слоя и заканчивая входным, используя градиенты ошибки по выходным значениям.

### **Отличия**

- Backpropagation позволяет эффективно вычислять градиенты функции потерь по параметрам сети, учитывая сложную структуру нейронной сети.
- В отличие от обычного вычисления градиентов, которое требует аналитических выражений для производных, backpropagation использует метод автоматического дифференцирования, что делает его применимым для любой архитектуры нейронной сети.

### **Преимущества**

- Эффективное вычисление градиентов: Backpropagation позволяет быстро вычислять градиенты функции потерь по параметрам сети, что ускоряет процесс обучения.
- Гибкость: Этот метод применим к нейронным сетям любой сложности и архитектуры.

### **Недостатки**

- Возможность застревания в локальных минимумах: Как и в случае с градиентным спуском, backpropagation может застрять в локальных минимумах функции потерь.
- Взрывные и исчезающие градиенты: В глубоких нейронных сетях могут возникать проблемы с исчезающими или взрывными градиентами, что затрудняет обучение.

# **Линейные слои в нейронных сетях**

Линейные слои - это основной строительный блок в нейронных сетях. Они представляют собой слои, в которых каждый входной нейрон связан с каждым выходным нейроном с определенным весом. В линейном слое нет нелинейной активации; он выполняет простое аффинное преобразование входных данных.

### **Формула**

Пусть *x* - вектор входных данных размерности $*n*$, а $*W*$ - матрица весов размерности $*m×n*$, где $*m*$ - количество нейронов в слое. Тогда выход $*y*$ линейного слоя может быть вычислен как:
$y=Wx+b$
Где $*b*$ - вектор смещений (bias), размерностью $*m×1*$.

### **Преимущества**

- Простота и эффективность в вычислениях.
- Широко используется в различных типах нейронных сетей.
- Легко интерпретируемы.

### **Недостатки**

- Ограниченная способность моделирования сложных нелинейных отношений между данными.
- Не способны сами по себе обучать сложные функции.
- Большое количество параметров, а следовательно большой размер и вес итоговой модели.

# Свёрточные слои (Convolutional Layers)

Свёрточные слои являются основным строительным блоком в свёрточных нейронных сетях (CNN). Они используются для обработки изображений и других типов данных с пространственной структурой. Основная идея свёрточных слоев заключается в том, чтобы автоматически извлекать признаки из входных данных путем применения фильтров (ядер) к различным областям входного изображения.

**Формула:**
Пусть $I$ - входное изображение, $K$ - ядро свёртки (фильтр), $b$ - смещение (bias), $S$ - шаг (stride), и $P$ - размер области дополнения (padding). Тогда выход $O$ свёрточного слоя может быть вычислен как:
$O_{i,j} = \sum_{m=0}^{M-1} \sum_{n=0}^{N-1} I_{(i+m),(j+n)} \cdot K_{m,n} + b$
где $M \times N$ - размер ядра свёртки.

### Количество обучаемых параметров в свёртке

Количество обучаемых параметров в свёрточном слое зависит от размера ядра свёртки, количества каналов входного изображения и числа фильтров (ядер) в слое.

Для одного фильтра размером $M \times N$ и $C_{\text{in}}$ каналов во входном изображении количество обучаемых параметров будет равно $M \times N \times C_{\text{in}} + 1$, где $+1$ учитывает смещение (bias). Если в свёрточном слое используется $C_{\text{out}}$ фильтров, то общее количество параметров будет равно $(M \times N \times C_{\text{in}} + 1) \times C_{\text{out}}$.

### Размер выхода свёртки

Размер выходного изображения после применения свёрточного слоя зависит от размера ядра свёртки, шага (stride) и области дополнения (padding).

Для входного изображения размером $H_{\text{in}} \times W_{\text{in}}$, ядра свёртки размером $M \times N$, шага $S$ и области дополнения $P$, размер выходного изображения будет рассчитываться следующим образом:

$H_{\text{out}} = \left\lfloor \frac{H_{\text{in}} - M + 2P}{S} \right\rfloor + 1$

$W_{\text{out}} = \left\lfloor \frac{W_{\text{in}} - N + 2P}{S} \right\rfloor + 1$

Здесь $\left\lfloor \cdot \right\rfloor$ обозначает операцию округления вниз до ближайшего целого числа.

**Преимущества:**

- **Локальность:** Свёрточные слои учитывают локальные зависимости в данных, что делает их эффективными для обработки изображений.
- **Параметры:** Параметры свёртки (фильтры) являются обучаемыми и позволяют моделировать различные типы признаков.
- **Совместное использование параметров:** Параметры фильтров разделяются между разными областями изображения, что позволяет моделировать общие признаки.

**Недостатки:**

- **Подвержены проблеме затухающих градиентов:** В глубоких сетях могут возникать проблемы с обучением из-за затухающих или взрывающихся градиентов.
- **Вычислительно сложны:** Свёрточные операции требуют больших вычислительных ресурсов, особенно при работе с большими изображениями и глубокими архитектурами.

Свёрточные слои являются ключевым компонентом свёрточных нейронных сетей и широко используются в обработке изображений, а также в других приложениях, где важна пространственная структура данных. Они позволяют автоматически извлекать иерархические признаки из входных данных, что делает их мощным инструментом для анализа и классификации различных типов данных.

# Инициализация весов

### **Нулевая инициализация (Zero Initialization)**

- **Преимущества:**
    - Простота в реализации.
- **Недостатки:**
    - **Симметрия градиентов:** При использовании нулевой инициализации всех весов симметрия градиентов приводит к тому, что все нейроны в каждом слое вычисляют одинаковое значение. Это приводит к тому, что все веса будут обновляться одинаково на каждой итерации обучения, что делает обучение бесполезным.
    - **Затухание градиентов:** Инициализация всех весов нулями может привести к проблеме затухания градиентов, когда градиенты становятся нулевыми и неспособными эффективно обновлять веса во время обратного распространения ошибки.
    - **Неэффективность обучения:** Из-за проблемы с симметрией и затуханием градиентов нейронная сеть, инициализированная нулями, обычно обучается очень медленно или вовсе не обучается.
- **Использование:**
    - Не рекомендуется из-за проблем с затуханием градиентов и недостаточной инициализацией весов.

P.S. Всё то же самое относится и к инициализации весов любой другой константой.

### **Случайная инициализация (Random Initialization)**

- **Преимущества:**
    - Простота в реализации.
    - Может быть эффективным для небольших моделей и небольших наборов данных.
- **Недостатки:**
    - Не гарантирует хорошую инициализацию весов для определенных типов архитектур или задач.
- **Использование:**
    - Этот метод может быть полезен для начального эксперимента с небольшими моделями или в случае, когда нет явных предпочтений относительно других методов.

### **Инициализация Хе (He Initialization, Kaiming Initialization)**

Представляет собой инициализацию весовых коэффициентов нейронной сети случайными значениями из нормального распределения со средним значением 0 и стандартным отклонением, рассчитанным на основе количества входных нейронов. Формула для расчета стандартного отклонения выглядит следующим образом:

$\text{stddev} = \sqrt{\frac{2}{n}}$

Где $*n*$ - количество входных нейронов.

- **Преимущества:**
    - Разработан специально для активаций ReLU, что обычно приводит к быстрой и стабильной сходимости.
- **Недостатки:**
    - Может быть более чувствителен к масштабированию входных данных.
- **Использование:**
    - Рекомендуется для глубоких нейронных сетей с функциями активации ReLU.

### **Инициализация Ксавьера (Xavier Initialization)**

$\text{stddev} = \sqrt{\frac{1}{n}}$

Где $*n*$ - количество входных нейронов.

- **Преимущества:**
    - Хорошо подходит для симметричных функций активации, таких как гиперболический тангенс (tanh) или сигмоидальная функция.
- **Недостатки:**
    - Может быть неэффективным для активаций ReLU.
- **Использование:**
    - Рекомендуется для моделей с симметричными функциями активации и небольшим количеством слоев.

# Attention

Это механизм в нейронных сетях, который позволяет модели сосредоточивать свое внимание на определенных частях входных данных в зависимости от их значимости для задачи, позволяет модели динамически вычислять веса для каждого элемента входных данных, чтобы выделить наиболее важные аспекты. Иными словами, это умное перевзвешивание признаков.

**Математическая формула**:
Пусть у нас есть набор входных признаков $*X*$ и вектор весов $*α*$, где каждый элемент $*α_i*$ представляет вес для соответствующего признака. Тогда контекстный вектор $*C*$ вычисляется следующим образом:

$C=∑_iα_i⋅X_i$

**Плюсы:**

- Позволяет модели концентрироваться на наиболее важных аспектах данных.
- Улучшает интерпретируемость модели.
- Помогает решать проблему долгосрочных зависимостей в последовательных данных.

**Минусы:**

- Увеличивает сложность модели и вычислений.
- Требует больше ресурсов для обучения и инференса.
- Может быть подвержен проблеме внимания на мусорные фичи, если не правильно настроен.

# Self Attention

Пусть мы имеем матрицу эмбеддингов $X$ размером $M \times N$, где $M$ - количество слов, а $N$ - длина эмбеддинг-вектора для каждого слова ($1 \times N$). Тогда наш self-attention имеет внутри себя 3 обучаемые матрицы весов - $W_q$, $W_k$, $W_v$, где:

- $W_q$ - матрица весов **query** размером $N \times K$, где $K$ - какое-то выбранное нами целое число
- $W_k$ - матрица весов **key** размером $N \times K$, где $K$ - какое-то выбранное нами целое число
- $W_v$ - матрица весов **value** размером $M \times M$

Тогда для каждого $x_i$ эмбеддинг-вектора при $i$ от 1 до $M$ путём матричного перемножения мы получаем следующее:

- $q_i = x_i W_q$ размером $1 \times K$, запрос, информация, которую мы хотим найти в текущем контексте
- $k_i  = x_i W_k$ размером $1 \times K$, информация, которую содержит слово в текущем контексте (если оно там встречается)
- $v_i = x_i W_v$ размером $1 \times K$, информация, которая нам интересная в конечном итоге, и которую мы будем “доставать” по нашим $q$ и $k$ (условно именно эта информация несёт какой-то общий смысл слова во всём “общении”)
- Чем больше похожи (сонаправлены) вектора $q_i$ и $k_i$, тем больше их скалярное произведение, и тем более тесная связь между стоящими за ними словами

**Пример**:
Если мы хотим посмотреть на связь $i$-слова с самим собой, то мы делаем $q_i \cdot k_i$, если хотим посмотреть на связь $i$-слова с ($i+1$)-словом, то делаем $q_i \cdot k_{i+1}$

![key_query_illustration.png](https://github.com/BejeweledMe/For-Interviews/blob/main/RU/Нейронные%20сети/key_query_illustration.png)

Для примера возьмём $i = 1$, тогда для первого слова мы получаем следующий вектор:
$\left( q_1 \cdot k_1, q_1 \cdot k_2, \dots, q_1 \cdot k_M \right)$, выраженный вещественными числами.
Опять же для примера пусть это будет вектор $a = \left( 14.3, 94.32, \dots, 1.1 \right)$.
Теперь нормируем наш вектор вектор $a$ следующим образом:

- $a = \frac{a}{\sqrt{M}}$, чтобы нормализовать распределение и помочь справиться со взрывами и затуханиями градиентов
- После чего применяем к вектору $a$ функцию **softmax**, чтобы сумма внутри вектора была равной 1.

![softmax_normalization.png](https://github.com/BejeweledMe/For-Interviews/blob/main/RU/Нейронные%20сети/softmax_normalization.png)

Далее мы считаем взвешенную сумму для нашего value-вектора $v_1$ - коэффициентами для этой суммы будут значения нашего вектора $a$. Соответственно, если проделать вышеописанные операции для каждого слова с каждым, то получаем следующую матрицу связи слов друг с другом, значения внутри которой характеризуют силу этой связи:

![words_relation_matrix.png](https://github.com/BejeweledMe/For-Interviews/blob/main/RU/Нейронные%20сети/words_relation_matrix.png)