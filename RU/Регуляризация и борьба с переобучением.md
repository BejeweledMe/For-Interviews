# Регуляризация и борьба с переобучением

# Bias-Variance Trade-off

Bias-variance trade-off - это концепция в машинном обучении, которая описывает компромисс между смещением (bias) и разбросом (variance) модели.

- **Смещение (bias)**: Это ошибка, возникающая из-за упрощенных предположений в модели. Модели с высоким смещением склонны к недообучению, что означает, что они не могут хорошо подстраиваться под данные и делать точные предсказания.
- **Разброс (variance)**: Это ошибка, возникающая из-за чрезмерной чувствительности модели к случайным изменениям в данных обучения. Модели с высоким разбросом склонны к переобучению, что означает, что они слишком точно подстраиваются под данные обучения и плохо обобщаются на новые данные.

Торговля между смещением и разбросом заключается в настройке модели таким образом, чтобы достигнуть оптимального баланса между недообучением и переобучением. Важно понимать, что уменьшение смещения обычно сопровождается увеличением разброса и наоборот. Поэтому важно найти оптимальный баланс для конкретной задачи машинного обучения.

Например, использование более сложных моделей (например, глубокие нейронные сети) может уменьшить смещение и улучшить качество предсказаний, но это может привести к увеличению разброса и увеличению риска переобучения на обучающем наборе данных. С другой стороны, использование более простых моделей может уменьшить разброс, но увеличить смещение и риск недообучения.

# L1 & L2

L1 и L2 регуляризация являются методами добавления штрафа за веса модели в функцию потерь во время обучения. Это приводит к тому, что веса модели становятся меньше, что уменьшает вероятность переобучения и повышает обобщающую способность модели. Выбор между L1 и L2 регуляризацией зависит от конкретного набора данных и целей моделирования. L1 часто используется для выбора важных признаков, тогда как L2 обычно используется для общего контроля над переобучением. Вот как они работают:

### **L1 (Lasso) регуляризация**

- В L1 регуляризации используется сумма абсолютных значений весов.
- L1 регуляризация может приводить к разреженности весов, так как она часто приводит к тому, что некоторые веса становятся нулевыми. Это позволяет выбирать наиболее информативные признаки и улучшает интерпретируемость модели.
- Однако L1 регуляризация может иметь тенденцию выбирать только один из нескольких признаков с похожими значениями, что может привести к потере информации.

Формула:

$Loss=\text{Original Loss} + \lambda \sum_{i=1}^{n} |w_i|$

*Где:*

- $*λ*$ - это коэффициент регуляризации, который контролирует величину штрафа
- *w_i* - веса модели.

### **L2 (Ridge) регуляризация**

- В L2 регуляризации используется сумма квадратов весов.
- L2 регуляризация обычно не приводит к разреженности весов, поскольку она уменьшает величину всех весов равномерно.
- L2 регуляризация часто более устойчива в сравнении с L1 и может быть более эффективной, если важны все признаки, а не только несколько.

Формула:
$Loss=\text{Original Loss} + \lambda \sum_{i=1}^{n} w_i^2$

Где:

- $*λ*$ - это коэффициент регуляризации, который контролирует величину штрафа
- *w_i* - веса модели.

# Dropout

**Преимущества:**

- Помогает предотвратить переобучение, уменьшая зависимость между нейронами.
- Улучшает обобщающую способность модели и ее устойчивость к изменениям в данных.

**Недостатки:**

- Может увеличить время обучения из-за необходимости проводить больше итераций.
- Во время инференса требуется масштабирование весов.

**Как работает:**

- Во время обучения каждый нейрон с вероятностью $(1 - p)$ сохраняется, а с вероятностью $p$ отключается.
- Во время инференса все нейроны остаются активными, но их веса масштабируются на $(1 - p)$.

# BatchNorm

**Преимущества:**

- Ускоряет обучение, уменьшая проблему взрывающегося или затухающего градиента.
- Улучшает стабильность обучения и помогает избежать переобучения.
- Позволяет использовать более высокие скорости обучения.

**Недостатки:**

- Может замедлить обучение на небольших мини-пакетах данных.
- Вводит дополнительные параметры в модель, что увеличивает ее сложность и затраты на вычисления.

**Как работает:**

- Нормализует активации по каждому признаку в мини-пакете данных.
- Во время обучения использует среднее и дисперсию по мини-пакету, а во время инференса использует накопленное среднее и дисперсию по всему набору данных.

Формула:

Для входных данных $X$ с признаками $\{x_1, x_2, ..., x_n\}$ по каждому мини-батчу:

1. **Вычисление среднего и дисперсии по мини-батчу:**

$\mu = \frac{1}{m} \sum_{i=1}^{m} x_i$

$\sigma^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu)^2$

2. **Нормализация данных:**
$\hat{x}_i = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}$
3. **Масштабирование и сдвиг:**
$y_i = \gamma \hat{x}_i + \beta$

Где:

- $\mu$ - среднее значение по мини-батчу
- $\sigma^2$ - дисперсия по мини-батчу
- $\epsilon$ - небольшая константа для численной стабильности
- $\gamma$ - обучаемый параметр масштаба (Scale)
- $\beta$ - обучаемый параметр сдвига (Shift)

Эти параметры $\gamma$ и $\beta$ обучаются вместе с остальными параметрами модели в процессе обучения сети.

# Аугментация данных

Аугментация данных - это процесс искусственного создания новых обучающих примеров путем применения различных трансформаций к существующим данным. Цель аугментации данных состоит в том, чтобы расширить набор обучающих данных, улучшить обобщающую способность модели и сделать ее более устойчивой к различным условиям и вариациям в данных. При аугментировании данных важно помнить, что нужно применять те трансформации, которые соответствуют природе данных, а не все подряд.

# Early Stopping

Метод регуляризации для предотвращения переобучения и оптимизации процесса обучения. Если выбранный нами критерий качества модели перестаёт улучшаться выбранное нами количество эпох, то останавливаем обучение.

**Преимущества:**

- Предотвращает переобучение и улучшает обобщающую способность модели.
- Снижает затраты времени и ресурсов на обучение.
- Улучшает интерпретируемость модели.

**Недостатки:**

- Может привести к недообучению, если обучение прекратится слишком рано.
- Неэффективен при больших колебаниях производительности модели.

# Скедулеры (Schedulers)

Скедулеры используются в процессе обучения нейронных сетей для динамического изменения параметров оптимизации (например, скорости обучения) в зависимости от хода обучения. Обычно параметры скедулера настраиваются в соответствии с эмпирическими наблюдениями или на основе опыта.

**Преимущества:**

- Помогают оптимизировать процесс обучения и улучшить производительность модели.
- Позволяют более гибко реагировать на динамику обучения и изменения в данных.

**Недостатки:**

- Не всегда просто подобрать правильные параметры скедулера, что может привести к ухудшению производительности модели.
- Могут увеличить сложность настройки модели и требовать дополнительного времени для экспериментов.

# Другие методы борьбы с переобучением

- Кросс-валидация
- Уменьшение размера и сложности модели
- Ансамблирование моделей
- Разные способы нормализации данных